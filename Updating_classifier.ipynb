{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9fd104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 22:52:12.294477: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad996335",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_folder = '/raid/mpsych/OMAMA/DATA/data/train'\n",
    "train_npz_folder = '/raid/mpsych/OMAMA/DATA/data/2d_resized_512/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139bac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists of image and npz files\n",
    "image_files = [os.path.join(train_image_folder, f) for f in os.listdir(train_image_folder) if f.endswith('.png')]\n",
    "npz_files = [os.path.join(train_npz_folder, f) for f in os.listdir(train_npz_folder) if f.endswith('.npz')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f65a3c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80bdae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(npz_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71309d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = image_files[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd20722",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_files = npz_files[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046868bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset (adjust the test_size as needed)\n",
    "train_files, test_files = train_test_split(list(zip(image_files, npz_files)), test_size=0.3, random_state=42)\n",
    "val_files, test_files = train_test_split(test_files, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36b8bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 512\n",
    "img_width = 512\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a2637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_generator(file_list, batch_size, img_height, img_width):\n",
    "    total_files = len(file_list)\n",
    "    indices = np.arange(total_files)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    while True:\n",
    "        for i in range(0, total_files, batch_size):\n",
    "            batch_indices = indices[i:i + batch_size]\n",
    "            batch_images = []\n",
    "            batch_npz = []\n",
    "            batch_labels = []\n",
    "\n",
    "            for idx in batch_indices:\n",
    "                img_file, npz_file = file_list[idx]\n",
    "\n",
    "                # Process image file\n",
    "                image = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)\n",
    "                image = cv2.resize(image, (img_width, img_height))\n",
    "                image = np.expand_dims(image, axis=-1)\n",
    "                batch_images.append(image)\n",
    "\n",
    "                # Process npz file\n",
    "                with np.load(npz_file, allow_pickle=True) as data:\n",
    "                    npz = data['data']\n",
    "                npz = np.expand_dims(npz, axis=-1)\n",
    "                batch_npz.append(npz)\n",
    "\n",
    "                # Assign class labels\n",
    "                batch_labels.append([1, 0] if img_file.endswith('.png') else [0, 1])\n",
    "\n",
    "            combined_batch = np.concatenate((batch_images, batch_npz), axis=-1)\n",
    "            yield (combined_batch, np.array(batch_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fecb088",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, min_delta=0.001, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06305b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f7c1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2309db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_generator = custom_data_generator(train_files, batch_size, img_height, img_width)\n",
    "val_generator = custom_data_generator(val_files, batch_size, img_height, img_width)\n",
    "test_generator = custom_data_generator(test_files, batch_size, img_height, img_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921e8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de71b1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 22:54:55.993230: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-11-20 22:54:56.149727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:4e:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-11-20 22:54:56.149768: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-11-20 22:54:56.153097: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-20 22:54:56.153144: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-11-20 22:54:56.154170: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-11-20 22:54:56.154570: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-11-20 22:54:56.155144: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-11-20 22:54:56.155975: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-11-20 22:54:56.156321: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-11-20 22:54:56.161795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-11-20 22:54:56.162418: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 22:54:56.165341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:4e:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2023-11-20 22:54:56.170633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-11-20 22:54:56.170668: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-11-20 22:54:56.643184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-11-20 22:54:56.643227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-11-20 22:54:56.643233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-11-20 22:54:56.651019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38425 MB memory) -> physical GPU (device: 0, name: A100-SXM4-40GB, pci bus id: 0000:4e:00.0, compute capability: 8.0)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                             activation='relu',\n",
    "                             input_shape=(img_height, img_width, 1)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(NUMBER_OF_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bda60917",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=\"adadelta\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8c8bba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 22:55:48.028057: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-11-20 22:55:48.047183: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2245720000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 22:56:01.073204: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-11-20 22:56:01.688470: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2023-11-20 22:56:02.391547: W tensorflow/stream_executor/gpu/asm_compiler.cc:191] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2023-11-20 22:56:02.391570: W tensorflow/stream_executor/gpu/asm_compiler.cc:194] Used ptxas at ptxas\n",
      "2023-11-20 22:56:02.391632: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Unimplemented: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-11-20 22:56:03.833429: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-11-20 22:56:04.624668: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-11-20 22:56:05.644173: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 378s 327ms/step - loss: 1.8344 - accuracy: 0.9935 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "1093/1093 [==============================] - 357s 322ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "1093/1093 [==============================] - 355s 325ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "234/234 [==============================] - 50s 213ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Test Loss: 0.0, Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_files) // batch_size,\n",
    "        epochs=3,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_files) // batch_size,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during training:\", str(e))\n",
    "\n",
    "# Model evaluation on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_files) // batch_size)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8dcd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0b453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ec89796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.55975455 0.44024542]]\n",
      "Predicted Class: 0\n"
     ]
    }
   ],
   "source": [
    "# 3 epochs\n",
    "test_file = '/raid/mpsych/OMAMA/DATA/data/train/sample_40069.png'\n",
    "test_image = cv2.imread(test_file, cv2.IMREAD_GRAYSCALE)\n",
    "test_image = cv2.resize(test_image, (img_width, img_height))\n",
    "test_image = np.expand_dims(test_image, axis=-1)\n",
    "test_image = test_image / 255.0\n",
    "test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
    "\n",
    "predictions = model.predict(test_image)\n",
    "print(\"Predictions:\", predictions)\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5e69be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.63113284 0.36886716]]\n",
      "Predicted Class: 0\n"
     ]
    }
   ],
   "source": [
    "# Load and process a synthetic (PNG) test image\n",
    "test_png_file = '/raid/mpsych/OMAMA/DATA/data/train/sample_10446.png'\n",
    "test_image = cv2.imread(test_file, cv2.IMREAD_GRAYSCALE)\n",
    "test_image = cv2.resize(test_image, (img_width, img_height))\n",
    "test_image = np.expand_dims(test_image, axis=-1)\n",
    "test_image = test_image / 255.0\n",
    "test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
    "\n",
    "predictions = model.predict(test_image)\n",
    "print(\"Predictions:\", predictions)\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71c5e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8036be3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.9863598  0.01364024]]\n",
      "Predicted Class: Real, Probability: 0.9863597750663757\n"
     ]
    }
   ],
   "source": [
    "test_npz_file = '/raid/mpsych/OMAMA/DATA/data/2d_resized_512/images/100220136299296817993264225430810813957.npz'\n",
    "\n",
    "with np.load(test_npz_file, allow_pickle=True) as data:\n",
    "    test_npz = data['data']\n",
    "\n",
    "# Preprocess the NPZ data as per your training data preprocessing\n",
    "# For example, if resizing and normalization were applied during training\n",
    "test_npz = cv2.resize(test_npz, (img_width, img_height))\n",
    "test_npz = np.expand_dims(test_npz, axis=-1)  # Add channel dimension if necessary\n",
    "test_npz = test_npz / 255.0  # Normalize if it was done during training\n",
    "test_npz = np.expand_dims(test_npz, axis=0)  # Add batch dimension\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(test_npz)\n",
    "print(\"Predictions:\", prediction)\n",
    "predicted_class = np.argmax(prediction)\n",
    "class_label = 'Real' if predicted_class == 0 else 'Synthetic'\n",
    "print(f\"Predicted Class: {class_label}, Probability: {np.max(prediction)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bdedc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efcfd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1fb18ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.4999916 0.5000084]]\n",
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# 3 epochs\n",
    "# test_file = '/raid/mpsych/OMAMA/DATA/data/train/sample_40069.png'\n",
    "# test_image = cv2.imread(test_file, cv2.IMREAD_GRAYSCALE)\n",
    "# test_image = cv2.resize(test_image, (img_width, img_height))\n",
    "# test_image = np.expand_dims(test_image, axis=-1)\n",
    "# test_image = test_image / 255.0\n",
    "# test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
    "\n",
    "# predictions = model.predict(test_image)\n",
    "# print(\"Predictions:\", predictions)\n",
    "# predicted_class = np.argmax(predictions)\n",
    "# print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c965c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
